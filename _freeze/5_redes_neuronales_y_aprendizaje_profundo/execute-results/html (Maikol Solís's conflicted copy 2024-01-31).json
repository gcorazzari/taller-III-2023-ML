{
  "hash": "d8af20caefba3951d5b053f1f521c0e7",
  "result": {
    "markdown": "# Redes neurales y Aprendizaje profundo\n\n## Perceptrón y redes neuronales\n\nEl perceptrón en el modelo más secillo de las neuronas. Se le llama también *neurona artificial*.\n\n![](./figuras/MLP01.svg){fig-align=\"center\"}\n\nLa idea es que cada uno de los *features* se multiplica por un peso $w_k$, se le suma un *bias* $b$ y al resultado de esta operación se le aplica la función de activación, que finalmente produce la salida $y$.\n\nEspecifícamente una red neuronal es una función anidada de funciones de la forma:\n\n\\begin{equation*}\ny = f_{NN}(x) = f_3(f_2(f_1(x))). \n\\end{equation*}\nen este caso, cada función $f_l$ es una función de la forma:\n\n\\begin{equation*}\nf_l(z) = f_l(W_lz + b_l)\n\\end{equation*}\ndonde \\(l\\) es el número de la cada capa o *layer* de la red, \\(W_l\\) es la matriz de pesos y \\(b_l\\) es el vector de *bias*. \n\n\n\n\nLas funciones de activación \\(f_l\\), deben ser preferiblemente diferenciable. Tres de las funciones más comunes son la función logística, la función tangente hiperbólica y la función lineal rectificada unitaria (ReLU):\n\n\\begin{equation*}\n\\text{logística: } f(x) = \\frac{1}{1+e^{-x}}\n\\end{equation*}\n\n\\begin{equation*}\n\\text{tangente hiperbólica: } f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n\\end{equation*}\n\n\\begin{equation*}\n\\text{ReLU: } f(x) = \\begin{cases}\n    0, & \\text{si } x < 0 \\\\\n    x, & \\text{en otro caso}\n\\end{cases}\n\\end{equation*}\n\nEn sí, el perceptrón es clasificador muy similar a la regresión logística. Sin embargo, es muy poco común que se utilice un solo perceptrón, sino que se utiliza varias capas (*layers*) de múltiples perceptrones, de manera que se pueda clasificar casos más complejos, a esto se le llama Perceptrón de capas múltiples (*Multiple Layer Perceptron*, MLP).\n\nUna capa está compuesta por varios perceptrones que están conectados con las entradas o con las salidas de la capa anterior, tal y como se muestra en la figura siguiente:\n\n![](./figuras/MLP02.svg){fig-align=\"center\"}\n\ncada uno de los bloques $P_{ij}$ es un perceptrón. En la figura, solo se tiene una salida, pero bien podría tenerse más, por lo que la capa de salida podría tener más de un perceptrón. De igual manera, se puede tener más de una capa escondida.\n\nLo que se debe hacer ahora es que, a partir de los datos que se tienen, encontrar los valores de los pesos $w_k$ y $b_k$, es decir, entrenar a la red.\n\n### Entrenamiento de la red neuronal\n\nPara entrenar la red, se debe buscar los valores. Para ello se minimiza una función de costo, como por ejemplo el error cuadrático medio.\n\n Para lograr la optimización se suele utilizar el descenso del gradiente, en un algoritmo llamado *Backpropagation*. Con el Backpropagation se calcula  el gradiente de la función de costo con respecto a los pesos de la red, de una manera eficiente. Se calculan el gradiente una capa a la vez , iterando hacia atrás desde la última capa.\n\n### Comandos en python\n\nCon la libraría scikit se puede crear y entrenar fácilmente una red neuronal.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.neural_network import MLPClassifier\n\n# Acá se cargan los datos\nX = [[0., 0.], [1., 1.]] # acá se pondría una lista de listas con los featrures\nY = [0, 1] # acá los labels\n\n# Acá se crea la red\nclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n\n# Acá se entrena la red\nclf.fit(X, Y)\n\n# Y acá se utiliza la red para predecir el valor de la salida para una nueva entrada\nclf.predict([[-1., -2.]])\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\narray([0])\n```\n:::\n:::\n\n\nen la variable **hidden_layer_sizes** se pone el número de perceptrones para cada una de las capas escondidas. **alpha** es la fuerza del término de regularización L2. El solver es el algoritmo de optimización:\n\n* `lbfgs` es un optimizador de la familia de métodos cuasi-Newton.\n* `sgd` se refiere al descenso estocástico del gradiente.\n* `adam` se refiere al optimizador estocástico del gradiente propuesto por Kingma, Diederik, and Jimmy Ba.\n\n\n## Aprendizaje profundo\n\nEl aprendizaje profundo implica entrenar redes neuronales con más de dos capas no salidas. En el pasado, entrenar redes con muchas capas era difícil debido a los problemas de gradiente explotante y gradiente desvaneciente, siendo este último particularmente intratable por décadas. El gradiente desvaneciente ocurre durante la actualización de parámetros en las redes neuronales mediante la retropropagación, un algoritmo eficiente que utiliza la regla de la cadena. Sin embargo, en algunas situaciones, el gradiente puede ser tan pequeño que impide el cambio de valor en algunos parámetros, deteniendo el entrenamiento de la red.\n\nLas funciones de activación tradicionales, como la tangente hiperbólica, tienen gradientes en el rango (0, 1), lo que hace que el gradiente se reduzca exponencialmente con el número de capas, resultando en un entrenamiento muy lento de las capas iniciales. No obstante, las implementaciones modernas permiten entrenar redes neuronales muy profundas, con cientos o miles de capas, gracias a técnicas como la función de activación ReLU, que sufre menos del problema de gradiente desvaneciente, y redes neuronales de memoria a corto plazo largo (LSTM), así como conexiones saltadas en redes neuronales residuales.\n\nEn la actualidad, dado que los problemas de gradiente explotante y desvaneciente están mayormente resueltos, el término \"aprendizaje profundo\" se refiere al entrenamiento de redes neuronales con herramientas algorítmicas y matemáticas modernas, independientemente de la profundidad de la red. En la práctica, muchos problemas empresariales se resuelven con redes neuronales de 2-3 capas ocultas entre las capas de entrada y salida.\n\n\n### Redes neuronales convolucionales\n\nLas redes neuronales convolucionales (CNN) son una clase de redes neuronales profundas, que se utilizan principalmente en el reconocimiento de imágenes y videos. Las CNN son muy similares a las redes neuronales estándar, pero en lugar de usar operaciones de matriz estándar en las capas ocultas, utilizan operaciones de convolución. Las CNN también incluyen operaciones de agrupación, que reducen la dimensionalidad de las características y aceleran el cálculo.\n\n![](./figuras/DL01.png){fig-align=\"center\"}\n\n\n:::{#exm-}\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom keras.datasets import fashion_mnist\n(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2024-01-29 17:07:58.441466: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nprint('Training data shape : ', train_X.shape, train_Y.shape)\n\nprint('Testing data shape : ', test_X.shape, test_Y.shape)\n\n# Find the unique numbers from the train labels\nclasses = np.unique(train_Y)\nnClasses = len(classes)\nprint('Total number of outputs : ', nClasses)\nprint('Output classes : ', classes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining data shape :  (60000, 28, 28) (60000,)\nTesting data shape :  (10000, 28, 28) (10000,)\nTotal number of outputs :  10\nOutput classes :  [0 1 2 3 4 5 6 7 8 9]\n```\n:::\n:::\n\n\nPodemos visualizar como se ve cada una de las imágenes:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nplt.figure(figsize=[5,5])\n\n# Display the first image in training data\nplt.subplot(121)\nplt.imshow(train_X[0,:,:], cmap='gray')\nplt.title(\"Ground Truth : {}\".format(train_Y[0]))\n\n# Display the first image in testing data\nplt.subplot(122)\nplt.imshow(test_X[0,:,:], cmap='gray')\nplt.title(\"Ground Truth : {}\".format(test_Y[0]))\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nText(0.5, 1.0, 'Ground Truth : 9')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](5_redes_neuronales_y_aprendizaje_profundo_files/figure-html/cell-5-output-2.png){width=418 height=231}\n:::\n:::\n\n\nlas imagenes son matrices de 28x28, por lo que se deben aplanar para poder ser utilizadas en la red neuronal. El tamaño de la imagen es debe de ser de 28x28x1. \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ntrain_X = train_X.reshape(-1, 28,28, 1)\ntest_X = test_X.reshape(-1, 28,28, 1)\ntrain_X.shape, test_X.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n((60000, 28, 28, 1), (10000, 28, 28, 1))\n```\n:::\n:::\n\n\nComo paso previo debemos convertir los datos a flotantes y normalizarlos:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ntrain_X = train_X.astype('float32')\ntest_X = test_X.astype('float32')\ntrain_X = train_X / 255.\ntest_X = test_X / 255.\n```\n:::\n\n\nAhora debemos convertir los labels a one-hot encoding:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Change the labels from categorical to one-hot encoding\ntrain_Y_one_hot = to_categorical(train_Y)\ntest_Y_one_hot = to_categorical(test_Y)\n\n# Display the change for category label using one-hot encoding\nprint('Original label:', train_Y[0])\nprint('After conversion to one-hot:', train_Y_one_hot[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOriginal label: 9\nAfter conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n```\n:::\n:::\n\n\nEsto quiere dercir que `train_Y_one_hot` es una matriz de 60000x10 donde cada fila indica la clase a la que pertenece la imagen.\n\nAhora debemos dividir los datos de entrenamiento en datos de entrenamiento y datos de validación:\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\ntrain_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\ntrain_X.shape,valid_X.shape,train_label.shape,valid_label.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))\n```\n:::\n:::\n\n\nEl modelo que se va a utilizar es el siguiente:\n\n![](./figuras/DL02.webp){fig-align=\"center\"}\n\nPrimero se importaran las librerías necesarias:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nimport keras\nfrom tensorflow.python.keras.models import Input\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\n\nbatch_size = 64\nepochs = 20\nnum_classes = 10\n```\n:::\n\n\nAhora si se crea el modelo:\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfashion_model = Sequential()\nfashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\nfashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(MaxPooling2D((2, 2),padding='same'))\nfashion_model.add(Dropout(0.25))\nfashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\nfashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model.add(Dropout(0.25))\nfashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\nfashion_model.add(LeakyReLU(alpha=0.1))                  \nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model.add(Dropout(0.4))\nfashion_model.add(Flatten())\nfashion_model.add(Dense(128, activation='linear'))\nfashion_model.add(LeakyReLU(alpha=0.1))           \nfashion_model.add(Dropout(0.3))\nfashion_model.add(Dense(num_classes, activation='softmax'))\n```\n:::\n\n\nCompilamos \n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\nfashion_model.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n Layer (type)                Output Shape              Param #   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d (Conv2D)             (None, 28, 28, 32)        320       \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n leaky_re_lu (LeakyReLU)     (None, 28, 28, 32)        0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n D)                                                              \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dropout (Dropout)           (None, 14, 14, 32)        0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 64)        0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n g2D)                                                            \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n leaky_re_lu_2 (LeakyReLU)   (None, 7, 7, 128)         0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n g2D)                                                            \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n flatten (Flatten)           (None, 2048)              0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense (Dense)               (None, 128)               262272    \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dropout_3 (Dropout)         (None, 128)               0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense_1 (Dense)             (None, 10)                1290      \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal params: 356234 (1.36 MB)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTrainable params: 356234 (1.36 MB)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNon-trainable params: 0 (0.00 Byte)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n:::\n\n\nEntremanos el modelo:\n\n::: {.cell cache='true' execution_count=12}\n``` {.python .cell-code}\nfashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n```\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\naccuracy = fashion_train_dropout.history['acc']\nval_accuracy = fashion_train_dropout.history['val_acc']\nloss = fashion_train_dropout.history['loss']\nval_loss = fashion_train_dropout.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n```\n:::\n\n\n:::\n\n",
    "supporting": [
      "5_redes_neuronales_y_aprendizaje_profundo_files"
    ],
    "filters": [],
    "includes": {}
  }
}