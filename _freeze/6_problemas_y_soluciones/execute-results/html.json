{
  "hash": "81038dc821b07d3a2f2ec0e06235cb91",
  "result": {
    "markdown": "# Problemas y soluciones\n\n## Regresión de Kernel\n\nLa regresión de Kernel es utilizada para los casos,  que la entrada es un vector de características D-dimensional, con D > 3. La regresión del kernel es un método no paramétrico. Eso significa que no hay parámetros que aprender. El modelo se basa en los datos mismos (como en kNN). En su forma más simple, en la regresión del kernel buscamos un modelo como este:\n\n$$\nf(x) = \\dfrac{1}{N}\\sum_{i=1}^{N}w_{i}y_{i}\n$$\n\n, donde\n$$\nw_{i} = \\dfrac{Nk(\\dfrac{x_{i}-x}{b}))}{\\sum_{i=1}^{N}k(\\dfrac{x_{k}-x}{b})}\n$$\n\nLa función k(·) es un núcleo(kernel). Puede tener diferentes formas, la más utilizada es el núcleo gaussiano:\n\n$$\nk(z)= \\dfrac{1}{\\sqrt{2\\pi}}exp(\\dfrac{-z^2}{2}).\n$$\n\nEl valor b es un hiperparámetro que ajustamos usando el conjunto de validación.\n\n:::{#exm-}\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n\nrng = np.random.RandomState(0)\ndata = np.linspace(0, 30, num=1_000).reshape(-1, 1)\ntarget = np.sin(data).ravel()\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ntraining_sample_indices = rng.choice(np.arange(0, 400), size=40, replace=False)\ntraining_data = data[training_sample_indices]\ntraining_noisy_target = target[training_sample_indices] + 0.5 * rng.randn(\n    len(training_sample_indices)\n)\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.plot(data, target, label=\"True signal\", linewidth=2)\nplt.scatter(\n    training_data,\n    training_noisy_target,\n    color=\"black\",\n    label=\"Noisy measurements\",\n)\nplt.legend()\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\n_ = plt.title(\n    \"Illustration of the true generative process and \\n\"\n    \"noisy measurements available during training\"\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-4-output-1.png){width=600 height=467}\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.linear_model import Ridge\n\nridge = Ridge().fit(training_data, training_noisy_target)\n\nplt.plot(data, target, label=\"True signal\", linewidth=2)\nplt.scatter(\n    training_data,\n    training_noisy_target,\n    color=\"black\",\n    label=\"Noisy measurements\",\n)\nplt.plot(data, ridge.predict(data), label=\"Lineal regression\")\nplt.legend()\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\n_ = plt.title(\"Limitation of a linear model such as ridge\")\n```\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-5-output-1.png){width=600 height=449}\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport time\n\nfrom sklearn.gaussian_process.kernels import ExpSineSquared\nfrom sklearn.kernel_ridge import KernelRidge\n\nkernel_ridge = KernelRidge(kernel=ExpSineSquared())\n\nstart_time = time.time()\nkernel_ridge.fit(training_data, training_noisy_target)\nprint(\n    f\"Fitting KernelRidge with default kernel: {time.time() - start_time:.3f} seconds\"\n)\n\nplt.plot(data, target, label=\"True signal\", linewidth=2, linestyle=\"dashed\")\nplt.scatter(\n    training_data,\n    training_noisy_target,\n    color=\"black\",\n    label=\"Noisy measurements\",\n)\nplt.plot(\n    data,\n    kernel_ridge.predict(data),\n    label=\"Kernel ridge\",\n    linewidth=2,\n    linestyle=\"dashdot\",\n)\nplt.legend(loc=\"lower right\")\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\n_ = plt.title(\n    \"Kernel ridge regression with an exponential sine squared\\n \"\n    \"kernel using default hyperparameters\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting KernelRidge with default kernel: 0.002 seconds\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-6-output-2.png){width=600 height=467}\n:::\n:::\n\n\nEste modelo ajustado no es exacto. De hecho, no configuramos los parámetros del kernel y en su lugar utilizamos los predeterminados. Podemos inspeccionarlos.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nkernel_ridge.kernel\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\nExpSineSquared(length_scale=1, periodicity=1)\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfrom scipy.stats import loguniform\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparam_distributions = {\n    \"alpha\": loguniform(1e0, 1e3),\n    \"kernel__length_scale\": loguniform(1e-2, 1e2),\n    \"kernel__periodicity\": loguniform(1e0, 1e1),\n}\nkernel_ridge_tuned = RandomizedSearchCV(\n    kernel_ridge,\n    param_distributions=param_distributions,\n    n_iter=500,\n    random_state=0,\n)\nstart_time = time.time()\nkernel_ridge_tuned.fit(training_data, training_noisy_target)\nprint(f\"Time for KernelRidge fitting: {time.time() - start_time:.3f} seconds\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime for KernelRidge fitting: 5.883 seconds\n```\n:::\n:::\n\n\nAjustar el modelo ahora es más costoso desde el punto de vista computacional ya que tenemos que probar varias combinaciones de hiperparámetros. Podemos echar un vistazo a los hiperparámetros encontrados para hacer algunas intuiciones.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nkernel_ridge_tuned.best_params_\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n{'alpha': 1.991584977345022,\n 'kernel__length_scale': 0.7986499491396734,\n 'kernel__periodicity': 6.6072758064261095}\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nstart_time = time.time()\npredictions_kr = kernel_ridge_tuned.predict(data)\nprint(f\"Time for KernelRidge predict: {time.time() - start_time:.3f} seconds\")\n\nplt.plot(data, target, label=\"True signal\", linewidth=2, linestyle=\"dashed\")\nplt.scatter(\n    training_data,\n    training_noisy_target,\n    color=\"black\",\n    label=\"Noisy measurements\",\n)\nplt.plot(\n    data,\n    predictions_kr,\n    label=\"Kernel ridge\",\n    linewidth=2,\n    linestyle=\"dashdot\",\n)\nplt.legend(loc=\"lower right\")\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\n_ = plt.title(\n    \"Kernel ridge regression with an exponential sine squared\\n \"\n    \"kernel using tuned hyperparameters\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime for KernelRidge predict: 0.006 seconds\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-10-output-2.png){width=600 height=467}\n:::\n:::\n\n\n:::\n\nFuente: <https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_compare_gpr_krr.html#sphx-glr-auto-examples-gaussian-process-plot-compare-gpr-krr-py>\n\n## Clasificación multiclase\n\nLa clasificación multiclase se refiere a aquellos casos en los que los datos contienen etiquetas que pertenecen a una de las $C$ clases:\n\n$$\ny \\in \\{1,...,C\\}\n$$\n\nPor ejemplo, se puede clasificar utilizando features extraídos de un set de imágenes de frutas. En este ejemplo las etiquetas `y` serían:\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ny = [\"manzana\", \"pera\", \"naranja\"]\n```\n:::\n\n\nCada imagen es una muestra y puede ser clasificada como **una** de las tres posibles clases. La clasificación multiclase asume que cada muestra está asociada a **una y solo una de las etiquetas**.\n\nEn el ejemplo, una fotografía no podría ser una pera y una naranja al mismo tiempo. Si esto no se cumple estaríamos ante un ejemplo de clasificación multietiqueta, que se verá más adelante.\n\nExisten algunos algoritmos de clasificación que se pueden extender para ser algoritmos de clasificación multiclase:\n\n- ID3 y otros algoritmos de árboles de decisión\n- Regresión logística reemplazando la función sigmoidal con la función softmax\n- kNN\n\nHay otros algoritmos que no se pueden extender a clasificación multiclase de forma simple, o en algunos casos, son mucho más eficientes en el caso de clasificación binaria. Ante esta situación, una estrategia común es llamada **uno versus el resto (OVR)**.\n\n### Uno versus el resto (OVR)\n\nLa idea detrás del enfoque de OVR es separar el problema de clasificación multiclase en múltiples casos de separación binaria.\n\nEn la siguiente figura podemos observar una ilustración con dos tipos de problemas de clasificación: binaria y multiclase.\n\n![Ilustración de problemas de clasificación](figuras/multiclass/img1.png){fig-alt=\"Problemas clasificación\" width=\"70%\"}\n\nPara la imagen de la derecha, un ejemplo de clasificación multiclase, podemos utilizar la estrategia de OVR, tal y como se muestra en la siguiente figura.\n\n![Ilustración de la clasificación multiclase](figuras/multiclass/img2.png){fig-alt=\"Clasificación multiclase\"}\n\n### Implementación en python\n\n**Imports:**\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\n\nimport numpy as np\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.datasets import make_classification\n\nimport time\n```\n:::\n\n\n**Creando datos aleatorios para clasificación:**\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Generando un array aleatorio de 1000 muestras, 10 features y una etiqueta de y=[0,1,2]\nX, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n\n# Separando el array en conjuntos de prueba (25 %) y entrenamiento (75 %)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\n# Colocando en dataframes para facilidad de presentación y graficación\ndf_train = pd.DataFrame({\"y\":y_train, \"x0\":X_train[:,0], \"x1\":X_train[:,1], \"x2\":X_train[:,2], \"x3\":X_train[:,3], \"x4\":X_train[:,4], \"x5\":X_train[:,5], \"x6\":X_train[:,6], \"x7\":X_train[:,7], \"x8\":X_train[:,8], \"x9\":X_train[:,9]})\n\ndf_test = pd.DataFrame({\"y\":y_test, \"x0\":X_test[:,0], \"x1\":X_test[:,1], \"x2\":X_test[:,2], \"x3\":X_test[:,3], \"x4\":X_test[:,4], \"x5\":X_test[:,5], \"x6\":X_test[:,6], \"x7\":X_test[:,7], \"x8\":X_test[:,8], \"x9\":X_test[:,9]})\n\ndf_train\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>-0.730468</td>\n      <td>0.397713</td>\n      <td>2.074811</td>\n      <td>3.268605</td>\n      <td>2.406136</td>\n      <td>-1.596750</td>\n      <td>-1.097254</td>\n      <td>0.839374</td>\n      <td>0.296566</td>\n      <td>-0.135522</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3.365775</td>\n      <td>-1.418898</td>\n      <td>1.872383</td>\n      <td>-0.693364</td>\n      <td>-3.133404</td>\n      <td>-2.877166</td>\n      <td>0.404063</td>\n      <td>-1.955554</td>\n      <td>-1.324028</td>\n      <td>1.988373</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-3.921299</td>\n      <td>0.641428</td>\n      <td>-2.026409</td>\n      <td>-2.679728</td>\n      <td>2.478175</td>\n      <td>4.280245</td>\n      <td>0.959757</td>\n      <td>-1.031408</td>\n      <td>2.619929</td>\n      <td>-1.552321</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>-0.476039</td>\n      <td>-0.361355</td>\n      <td>0.966933</td>\n      <td>2.514187</td>\n      <td>3.982157</td>\n      <td>-1.931150</td>\n      <td>-0.354184</td>\n      <td>2.025803</td>\n      <td>-0.295005</td>\n      <td>-2.314401</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>-0.119220</td>\n      <td>-0.421085</td>\n      <td>0.706323</td>\n      <td>0.561597</td>\n      <td>-0.483120</td>\n      <td>0.058308</td>\n      <td>-0.852335</td>\n      <td>-0.952946</td>\n      <td>-0.161098</td>\n      <td>0.587163</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>2</td>\n      <td>-0.707565</td>\n      <td>-4.271104</td>\n      <td>1.374571</td>\n      <td>-0.328230</td>\n      <td>6.264860</td>\n      <td>-2.072022</td>\n      <td>0.239431</td>\n      <td>-1.271852</td>\n      <td>-0.637552</td>\n      <td>-5.091475</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>1</td>\n      <td>-0.514813</td>\n      <td>-0.473396</td>\n      <td>-2.421689</td>\n      <td>-1.699244</td>\n      <td>-0.952055</td>\n      <td>2.352776</td>\n      <td>-0.218440</td>\n      <td>0.078120</td>\n      <td>-0.600584</td>\n      <td>-0.977306</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>0</td>\n      <td>2.273762</td>\n      <td>1.123171</td>\n      <td>0.927239</td>\n      <td>2.014521</td>\n      <td>-1.140324</td>\n      <td>-2.785479</td>\n      <td>0.158036</td>\n      <td>2.155000</td>\n      <td>-0.954108</td>\n      <td>1.196839</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>0</td>\n      <td>5.365061</td>\n      <td>-7.979364</td>\n      <td>3.641793</td>\n      <td>0.967290</td>\n      <td>3.271363</td>\n      <td>-8.028106</td>\n      <td>-0.642597</td>\n      <td>-1.656500</td>\n      <td>-5.257335</td>\n      <td>-4.871621</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>1</td>\n      <td>0.202570</td>\n      <td>1.402667</td>\n      <td>1.272342</td>\n      <td>3.307607</td>\n      <td>-1.209962</td>\n      <td>-0.738314</td>\n      <td>-1.770443</td>\n      <td>1.023892</td>\n      <td>-0.361837</td>\n      <td>1.986999</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 11 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nax = sns.scatterplot(data=df_train, x=\"x0\", y=\"x1\", hue=\"y\", palette=\"tab10\")\n```\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-14-output-1.png){width=587 height=429}\n:::\n:::\n\n\n**Definiendo el modelo OVR**\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Se define el modelo a usar dentro del OVR, en este caso SVC, puede ser logistico u otro\nmodelo = SVC()\n# Entrenando el modelo con los datos de entrenamiento\nclasificador = OneVsRestClassifier(modelo).fit(X_train, y_train)\n```\n:::\n\n\n**Probando el modelo OVR `clasificador`**\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Probando el modelo con los datos de prueba\nprediccion = clasificador.predict(X_test)\n\n# Colocando los datos predichos en un dataframe\ndf_pred = pd.DataFrame({\"y\":prediccion, \"x0\":X_test[:,0], \"x1\":X_test[:,1], \"x2\":X_test[:,2], \"x3\":X_test[:,3], \"x4\":X_test[:,4], \"x5\":X_test[:,5], \"x6\":X_test[:,6], \"x7\":X_test[:,7], \"x8\":X_test[:,8], \"x9\":X_test[:,9]})\n```\n:::\n\n\n¿Cuál es el resultado del modelo `clasificador`?\n\nNos da un vector con las etiquetas predichas:\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nprint(prediccion)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[2 0 2 2 0 0 0 1 0 2 2 2 2 0 1 2 1 0 0 0 1 2 2 2 2 1 0 1 0 0 1 0 1 2 0 1 1\n 0 1 2 0 1 0 2 2 0 0 0 2 2 1 1 1 0 2 2 1 0 2 0 0 0 0 2 2 1 1 2 2 1 1 1 2 0\n 0 0 1 0 0 2 1 2 0 1 1 0 1 0 2 2 0 2 1 2 2 0 2 2 1 0 1 2 1 2 2 0 2 1 1 0 2\n 0 0 0 2 2 2 2 0 2 0 0 1 2 2 2 0 1 0 0 0 2 0 0 0 0 1 0 1 2 0 1 0 1 2 2 1 2\n 1 0 2 2 1 1 2 1 1 0 1 2 2 0 2 0 0 1 0 0 1 0 1 0 1 0 2 1 2 0 0 0 0 1 0 1 0\n 2 0 2 2 0 0 1 0 2 0 0 1 2 0 2 0 1 2 2 1 2 1 2 2 2 2 0 1 1 2 2 1 0 2 0 2 2\n 0 0 1 0 0 0 1 0 1 1 1 0 2 1 0 0 0 0 1 2 1 1 1 0 0 1 1 2]\n```\n:::\n:::\n\n\nY con el método `score(X, y)` podemos obtener la *mean accuracy*, que es una métrica bastante exigente pues requiere que para cada muestra la etiqueta sea asignada correctamente:\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nprint(\"mean accuracy = \",clasificador.score(X_test, y_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmean accuracy =  0.908\n```\n:::\n:::\n\n\nLuego, podemos comparar la gráfica del conjunto de prueba `df_test`, utilizando por ejemplo los features $x_0$ y $x_1$:\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nax2 = sns.scatterplot(data=df_test, x=\"x0\", y=\"x1\", hue=\"y\", palette=\"tab10\")\n```\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-19-output-1.png){width=587 height=429}\n:::\n:::\n\n\nCon la gráfica utilizando los mismos features $x_0$ y $x_1$ del conjunto de prueba pero esta vez con las etiquetas predichas por el modelo. Se marca una *x* roja sobre los puntos que fueron clasificados incorrectamente:\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nax2 = sns.scatterplot(data=df_pred, x=\"x0\", y=\"x1\", hue=\"y\", palette=\"tab10\")\n# Compara los y de prueba vs. los y predichos para marcar los que no se clasificaron correctamente\nfor i in range(len(prediccion)):\n    if prediccion[i] != y_test[i]:\n        ax2.plot(df_pred[\"x0\"].iloc[i], df_pred[\"x1\"].iloc[i], \"rx\")\n```\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-20-output-1.png){width=587 height=429}\n:::\n:::\n\n\n## Clasificación con una clase\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# Generate and plot a synthetic imbalanced classification dataset\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom matplotlib import pyplot\nfrom numpy import where\n\n# define dataset\nX, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n n_clusters_per_class=1, weights=[0.999], flip_y=0, random_state=4)\n# summarize class distribution\ncounter = Counter(y)\nprint(counter)\n# scatter plot of examples by class label\nfor label, _ in counter.items():\n row_ix = where(y == label)[0]\n pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\npyplot.legend()\npyplot.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCounter({0: 9990, 1: 10})\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-21-output-2.png){width=569 height=411}\n:::\n:::\n\n\nSe ajusta el modelo correspondiente\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.svm import OneClassSVM\n# split into train/test sets\ntrainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n# define outlier detection model\nmodel = OneClassSVM(gamma='scale', nu=0.01)\n# fit on majority class\ntrainX_clean = trainX[trainy==0]\nmodel.fit(trainX_clean)\n# detect outliers in the test set\nyhat = model.predict(testX)\n# mark inliers 1, outliers -1\ntesty_clean = testy.copy()\ntesty_clean[testy == 1] = -1\ntesty_clean[testy == 0] = 1\n# calculate score\nscore = f1_score(testy_clean, yhat, pos_label=-1)\nprint('F1 Score: %.3f' % score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nF1 Score: 0.123\n```\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n# define the meshgrid\nx_min, x_max = trainX[:, 0].min() - 5, trainX[:, 0].max() + 5\ny_min, y_max = trainX[:, 1].min() - 5, trainX[:, 1].max() + 5\n\nx_ = np.linspace(x_min, x_max, 500)\ny_ = np.linspace(y_min, y_max, 500)\n\nxx, yy = np.meshgrid(x_, y_)\n\n# evaluate the decision function on the meshgrid\nz = model.decision_function(np.c_[xx.ravel(), yy.ravel()])\nz = z.reshape(xx.shape)\n\n# plot the decision function and the reduced data\nplt.contourf(xx, yy, z, cmap=plt.cm.PuBu)\na = plt.contour(xx, yy, z, levels=[0], linewidths=2, colors='darkred')\nb = plt.scatter(trainX[trainy == 0, 0], trainX[trainy == 0, 1], c='white', edgecolors='k')\nc = plt.scatter(trainX[trainy == 1, 0], trainX[trainy == 1, 1], c='gold', edgecolors='k')\nplt.legend([a.collections[0], b, c], ['learned frontier', 'regular observations', 'abnormal observations'], bbox_to_anchor=(1.05, 1))\nplt.axis('tight')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/4d/qj4qr8zx1n36td0hlt0p7x_h0000gn/T/ipykernel_24081/4105701295.py:21: MatplotlibDeprecationWarning:\n\nThe collections attribute was deprecated in Matplotlib 3.8 and will be removed two minor releases later.\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-23-output-2.png){width=588 height=411}\n:::\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nimport time\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import svm\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.datasets import make_blobs, make_moons\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.kernel_approximation import Nystroem\nfrom sklearn.linear_model import SGDOneClassSVM\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.pipeline import make_pipeline\n\nmatplotlib.rcParams[\"contour.negative_linestyle\"] = \"solid\"\n\n# Example settings\nn_samples = 300\noutliers_fraction = 0.15\nn_outliers = int(outliers_fraction * n_samples)\nn_inliers = n_samples - n_outliers\n\n# define outlier/anomaly detection methods to be compared.\n# the SGDOneClassSVM must be used in a pipeline with a kernel approximation\n# to give similar results to the OneClassSVM\nanomaly_algorithms = [\n    (\n        \"Robust covariance\",\n        EllipticEnvelope(contamination=outliers_fraction, random_state=42),\n    ),\n    (\"One-Class SVM\", svm.OneClassSVM(nu=outliers_fraction, kernel=\"rbf\", gamma=0.1)),\n    (\n        \"One-Class SVM (SGD)\",\n        make_pipeline(\n            Nystroem(gamma=0.1, random_state=42, n_components=150),\n            SGDOneClassSVM(\n                nu=outliers_fraction,\n                shuffle=True,\n                fit_intercept=True,\n                random_state=42,\n                tol=1e-6,\n            ),\n        ),\n    ),\n    (\n        \"Isolation Forest\",\n        IsolationForest(contamination=outliers_fraction, random_state=42),\n    ),\n    (\n        \"Local Outlier Factor\",\n        LocalOutlierFactor(n_neighbors=35, contamination=outliers_fraction),\n    ),\n]\n\n# Define datasets\nblobs_params = dict(random_state=0, n_samples=n_inliers, n_features=2)\ndatasets = [\n    make_blobs(centers=[[0, 0], [0, 0]], cluster_std=0.5, **blobs_params)[0],\n    make_blobs(centers=[[2, 2], [-2, -2]], cluster_std=[0.5, 0.5], **blobs_params)[0],\n    make_blobs(centers=[[2, 2], [-2, -2]], cluster_std=[1.5, 0.3], **blobs_params)[0],\n    4.0\n    * (\n        make_moons(n_samples=n_samples, noise=0.05, random_state=0)[0]\n        - np.array([0.5, 0.25])\n    ),\n    14.0 * (np.random.RandomState(42).rand(n_samples, 2) - 0.5),\n]\n\n# Compare given classifiers under given settings\nxx, yy = np.meshgrid(np.linspace(-7, 7, 150), np.linspace(-7, 7, 150))\n\nplt.figure(figsize=(len(anomaly_algorithms) * 2 + 4, 12.5))\nplt.subplots_adjust(\n    left=0.02, right=0.98, bottom=0.001, top=0.96, wspace=0.05, hspace=0.01\n)\n\nplot_num = 1\nrng = np.random.RandomState(42)\n\nfor i_dataset, X in enumerate(datasets):\n    # Add outliers\n    X = np.concatenate([X, rng.uniform(low=-6, high=6, size=(n_outliers, 2))], axis=0)\n\n    for name, algorithm in anomaly_algorithms:\n        t0 = time.time()\n        algorithm.fit(X)\n        t1 = time.time()\n        plt.subplot(len(datasets), len(anomaly_algorithms), plot_num)\n        if i_dataset == 0:\n            plt.title(name, size=18)\n\n        # fit the data and tag outliers\n        if name == \"Local Outlier Factor\":\n            y_pred = algorithm.fit_predict(X)\n        else:\n            y_pred = algorithm.fit(X).predict(X)\n\n        # plot the levels lines and the points\n        if name != \"Local Outlier Factor\":  # LOF does not implement predict\n            Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])\n            Z = Z.reshape(xx.shape)\n            plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"black\")\n\n        colors = np.array([\"#377eb8\", \"#ff7f00\"])\n        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[(y_pred + 1) // 2])\n\n        plt.xlim(-7, 7)\n        plt.ylim(-7, 7)\n        plt.xticks(())\n        plt.yticks(())\n        plt.text(\n            0.99,\n            0.01,\n            (\"%.2fs\" % (t1 - t0)).lstrip(\"0\"),\n            transform=plt.gca().transAxes,\n            size=15,\n            horizontalalignment=\"right\",\n        )\n        plot_num += 1\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](6_problemas_y_soluciones_files/figure-html/cell-24-output-1.png){width=1309 height=1199}\n:::\n:::\n\n\n## Clasificación multi-etiqueta\n\nEn la clasificación multietiqueta, cada ejemplo de entrenamiento no tiene sólo una etiqueta, sino varias. de ellas. Por ejemplo, si queremos describir una imagen, podríamos asignarle varias etiquetas: \"gente\", \"concierto\", \"naturaleza\", o las tres a la vez.\n\nSi el número de valores posibles para las etiquetas es elevado, pero todos son de la misma naturaleza, se puede optar por transformar cada ejemplo etiquetado en varios ejemplos etiquetados, uno por etiqueta. Estos nuevos ejemplos tienen todos el mismo vector de características y una sola etiqueta. Esto se convierte en un problema de clasificación multiclase.Se puede resolver utilizando la estrategia de uno contra el resto. La única diferencia con el problema multiclase habitual es que se genera un nuevo hiperparámetro: Threshold (umbral).\n\nSi la puntuación de predicción para alguna etiqueta está por encima del umbral, esta etiqueta se predice para el vector de características de entrada. En este escenario, se pueden predecir múltiples etiquetas para un solo vector de características.El valor del umbral se elige utilizando el conjunto de validación. De forma análoga, los algoritmos que pueden convertirse de forma natural en multiclase (árboles de decisión, regresión logística y redes neuronales, entre otros) pueden aplicarse a problemas de clasificación multietiqueta, ya que, estos devuelven la puntuación de cada clase, entonces se puede definir un umbral y asignar varias etiquetas a un vector de características si el umbral está por encima de un valor elegido, usando de forma experimental el conjunto de validación.\n\nLos algoritmos de redes neuronales pueden entrenar de forma natural modelos de clasificación multietiqueta utilizando la función de costo de entropía cruzada binaria. La capa de salida de la red neuronal, en este caso,tiene una unidad por etiqueta. Cada unidad de la capa de salida tiene la función de activación sigmoidea.\n\nEn los casos en los que el número de posibles valores que puede tomar cada etiqueta es pequeño, se puede converti en un problema multiclase utilizando un enfoque diferente. Imaginemos el siguiente problema. Se quiere etiquetar imágenes y las etiquetas pueden ser de dos tipos. El primer tipo de etiqueta puede tener dos valores posibles: {foto, pintura}; la etiqueta del segundo tipo puede tener tres valores posibles valores {retrato, paisaje, otro}. Se puede crear una nueva clase falsa para cada combinación de las dos clases originales, así:\n\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Tabla</title>\n    <style>\n        table {\n            width: 100%;\n            border-collapse: collapse;\n        }\n        th, td {\n            border: 1px solid #dddddd;\n            text-align: left;\n            padding: 8px;\n        }\n        th {\n            background-color: #f2f2f2;\n        }\n    </style>\n</head>\n<body>\n    <table>\n        <thead>\n            <tr>\n                <th>Clase falsa</th>\n                <th>Clase real 1</th>\n                <th>Clase real 2</th>\n            </tr>\n        </thead>\n        <tbody>\n            <tr>\n                <td>1</td>\n                <td>Foto</td>\n                <td>Retrato</td>\n            </tr>\n            <tr>\n                <td>2</td>\n                <td>Foto</td>\n                <td>Paisaje</td>\n            </tr>\n            <tr>\n                <td>3</td>\n                <td>Foto</td>\n                <td>Otro</td>\n            </tr>\n             <tr>\n                <td>4</td>\n                <td>Pintura</td>\n                <td>Retrato</td>\n            </tr>\n             <tr>\n                <td>5</td>\n                <td>Pintura</td>\n                <td>Paisaje</td>\n            </tr>\n             <tr>\n                <td>6</td>\n                <td>Pintura</td>\n                <td>Otro</td>\n            </tr>\n        </tbody>\n    </table>\n</body>\n</html>\n\nAhora se tienen los mismos ejemplos etiquetados, se sustituyen las etiquetas múltiples reales por una etiqueta falsa con valores de 1 a 6. Este enfoque funciona bien en la práctica cuando no hay demasiadas combinaciones posibles de clases. De lo contrario, es necesario utilizar muchos más datos de entrenamiento para compensar el aumento del número de clases.\n\nLa principal ventaja de este enfoque es que mantiene correlacionadas las etiquetas, al contrario que los métodos vistos anteriormente que predicen cada etiqueta independientemente de la otra. La correlación entre etiquetas puede ser una propiedad esencial en muchos problemas. Por ejemplo, si quiere predecir si un mensaje de correo electrónico es spam o no_spam al mismo tiempo que como predecir si es correo ordinario o prioritario.\n\n### Ejemplo código\n\n#### Formato de destino\n\nUna representación válida de multi etiqueta es una matriz binaria y de forma densa o escasa . Cada columna representa una clase. Los 1' en cada fila indican las clases positivas con las que se ha etiquetado una muestra. Un ejemplo de matriz densa para 3 muestras:(n_samples, n_classes)\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nimport numpy as np\ny = np.array([[1, 0, 0, 1], [0, 0, 1, 1], [0, 0, 0, 0]])\nprint(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1 0 0 1]\n [0 0 1 1]\n [0 0 0 0]]\n```\n:::\n:::\n\n\nTambién se pueden crear matrices densas utilizando MultiLabelBinarizer\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nimport numpy as np\nimport scipy.sparse as sparse\n\ny = np.array([[1, 0, 0, 1], [0, 0, 1, 1], [0, 0, 0, 0]])\ny_sparse = sparse.csr_matrix(y)\nprint(y_sparse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (0, 0)\t1\n  (0, 3)\t1\n  (1, 2)\t1\n  (1, 3)\t1\n```\n:::\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_multilabel_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, hamming_loss\n\n# Generate synthetic multi-label dataset\nX, y = make_multilabel_classification(n_samples=100, n_features=10, n_classes=5, random_state=42)\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a multi-label classifier\nclassifier = MultiOutputClassifier(KNeighborsClassifier())\n\n# Train the classifier\nclassifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = classifier.predict(X_test)\n\n# Calculate accuracy and Hamming loss\naccuracy = accuracy_score(y_test, y_pred)\nhamming_loss = hamming_loss(y_test, y_pred)\n\nprint(\"Hamming Loss:\", hamming_loss)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHamming Loss: 0.21\n```\n:::\n:::\n\n\n",
    "supporting": [
      "6_problemas_y_soluciones_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}